# 🤖 Система классификации токсичного аудио-контента

Бот для автоматической классификации голосовых сообщений на предмет токсичности с использованием машинного обучения и современных языковых моделей.

## 🎥 Демо

[📹 Посмотреть демо работы бота](https://drive.google.com/file/d/1wKuYMB56sTEMYNen2od8fVtglyJEcBlJ/view?usp=drive_link)

## 📋 Описание проекта

Проект представляет собой комплексное решение для модерации аудио-контента, состоящее из:
- **Telegram-бота** для приема голосовых сообщений
- **Модуля классификации** на базе DistilBERT
- **Интеграции с Google Gemini** для транскрипции аудио в текст

## 🎯 Классификация контента

Система классифицирует контент на **3 категории**:
- **0. Токсичный** — содержащий угрозы, агрессию, обещание совершить насильственные действия
- **1. Оскорбительный** — содержащий уничижительные высказывания, но без явной угрозы  
- **2. Нейтральный** — без признаков токсичности или оскорблений

## 🏗️ Архитектура системы

```
┌─────────────────┐    ┌──────────────────┐    ┌─────────────────┐
│   Telegram Bot  │───▶│  Google Gemini   │───▶│  Agent Module   │
│                 │    │  (STT)           │    │  (DistilBERT)   │
└─────────────────┘    └──────────────────┘    └─────────────────┘
```

### Компоненты:

1. **`bot/`** - Telegram-бот на aiogram
   - Принимает голосовые сообщения
   - Отправляет аудио на транскрипцию через Google Gemini
   - Использует агент как модуль для классификации

2. **`agent/`** - Модуль классификации
   - Использует DistilBERT для анализа текста
   - Импортируется как модуль в бота
   - Не требует отдельного запуска

3. **`training/`** - Модели машинного обучения
   - Логистическая регрессия (LogReg)
   - Нейронные сети (CNN, RNN)
   - Transformer модель (DistilBERT)

4. **`datasets/`** - Обучающие данные
   - Английский датасет токсичных комментариев
   - Русский датасет токсичных комментариев


## 🚀 Установка и запуск

### Требования:
```bash
pip install -r requirements.txt
```

### Переменные окружения:
```bash
# .env файл
TELEGRAM_BOT_TOKEN=your_telegram_bot_token
GOOGLE_API_KEY=your_google_api_key
```

### Запуск:

**Telegram-бот (из корня проекта):**
```bash
python -m bot.bot
```

> **Примечание:** Агент автоматически импортируется как модуль и не требует отдельного запуска. Модель DistilBERT включена в репозиторий через Git LFS.

## 📊 Результаты

## 📊 Сравнительная таблица моделей

| Модель              | Метрики                                         |
|---------------------|-------------------------------------------------|
| DistilBERT          | Accuracy: 96.36%, F1-score: 96.36% (EN+RU)      |
| BiLSTM (MLebedeva)  | Accuracy: 96.11%, F1-score: 89.89% (RU)         |
| BiLSTM (MLebedeva)  | Accuracy: 94.71%, F1-score: 72.25% (EN)         |
| BiLSTM              | Accuracy: 91.00% (EN+RU)                        |
| BiGRU               | Accuracy: 90.29% (EN+RU)                        |
| CNN                 | Accuracy: 89.27%, F1-score: 75.42% (EN+RU)      |
| CNN (Base)          | Accuracy: 89.39% (EN+RU)                        |

### 🏆 Выбор модели
**DistilBERT** показал наилучшие результаты и выбран для продакшена благодаря:
- Высокой точности (96.36%)
- Мультиязычной поддержке
- Компактному размеру (66M параметров)
- Быстрому инференсу


## 📁 Структура проекта

```
Toxic_classification/
├── bot/                    # Telegram-бот
│   ├── bot.py
│   └── schemas.py
├── agent/                  # Модуль классификации
│   ├── agent.py
│   ├── so_schemas.py
│   └── requirements.txt
├── api/                    # API для тестирования (не используется в продакшене)
│   ├── main.py
│   └── schemas.py
├── models/                 # Обученная модель DistilBERT (Git LFS)
│   ├── config.json
│   ├── model.safetensors   # Основная модель (520MB)
│   ├── tokenizer.json
│   ├── tokenizer_config.json
│   ├── special_tokens_map.json
│   ├── training_args.bin
│   ├── training_args/     # Дополнительные параметры обучения
│   └── README.md
├── training/               # Обучение моделей
│   ├── toxic_transformer.ipynb           # Transformer DistilBERT (лучшая модель)
│   ├── Toxic_class_logreg_eng.ipynb       # Логистическая регрессия (английский)
│   ├── Toxic_class_logreg_ru.ipynb        # Логистическая регрессия (русский)
│   ├── MLebedeva_toxic_bilstm_95_pipeline_eng.ipynb  # BiLSTM (английский)
│   ├── MLebedeva_toxic_bilstm_95_pipeline_rus.ipynb  # BiLSTM (русский)
│   ├── Toxic_class_base.ipynb             # Базовая модель
│   ├── Toxic_class_base_v2.ipynb          # Улучшенная базовая модель
│   ├── cc.en.300.bin                      # FastText эмбеддинги (английский)
│   └── cc.en.300.bin.gz                   # Сжатые эмбеддинги
├── datasets/               # Обучающие данные
│   ├── eng_toxic_full_df.csv              # Английский датасет токсичных комментариев
│   └── rus_toxic_full_df.csv              # Русский датасет токсичных комментариев
├── reports/                # Отчеты и документация
│   ├── Отчет_детектор_токсичности.pdf
│   ├── Техническое_описание_датасетов_Команды_5.pdf
│   └── Комментарии_NLP_.docx
├── requirements.txt        # Основные зависимости проекта
├── .gitignore             # Исключения для Git
├── .gitattributes         # Настройки Git LFS
└── README.md              # Документация проекта
```

## 🔧 Технические детали

### Интеграции:
- **Google Gemini 2.5 Pro** - транскрипция аудио
- **DistilBERT** - классификация текста
- **aiogram** - Telegram Bot API


## 👥 Команда

Проект выполнен в рамках курса NLP (Семестр 3)
1. Климов Святослав Дмитриевич
2. Алиев Эльхан Вагиф оглы
3. Веретнова Мария Рашитовна
4. Балабанова Алевтина Сергеевна
5. Лебедева Марина Сергеевна
6. Шельпякова Марианна Борисовна
7. Галиева Анна Борисовна

